{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNn6CPv4v9ejth7pYJoVE76"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KYrkmxC91bzZ"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier \n","from sklearn.svm import SVC\n","from sklearn.datasets import load_iris\n","from sklearn.datasets import load_files"]},{"cell_type":"code","source":["iris = load_iris()\n","\n","X = iris.data\n","y = iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n","\n","dt_clf = DecisionTreeClassifier()\n","svc_clf = SVC()\n","knn_clf = KNeighborsClassifier()\n","\n","klasyfikatory = [dt_clf, svc_clf, knn_clf]\n","\n","for clf in klasyfikatory:\n","    print(\"--------------\")\n","    print(\"fitting - training...\")\n","    clf.fit(X_train, y_train)\n","\n","    print(\"training on whole dataset...\")\n","    clf.fit(X, y)\n","\n","    print(\"predicting...\")\n","    y_pred = clf.predict(X_test)\n","\n","    print(\"true values \", y[:10])\n","    print(\"predicted   \", y_pred[:10])\n","\n","    print(\"scoring...\")\n","\n","    clf_score = clf.score(X_train, y_train)\n","    print(\"Train score = \", clf_score)\n","\n","    clf_score = clf.score(X_test, y_test)\n","    print(\"Test score = \", clf_score)\n","\n","    clf_score = clf.score(X, y)\n","    print(\"whole set score = \", clf_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqCM8Csv2QH-","executionInfo":{"status":"ok","timestamp":1670791494423,"user_tz":-60,"elapsed":4,"user":{"displayName":"Mateusz Budka","userId":"13585465409693320305"}},"outputId":"dc19439f-f7ae-4ca7-a454-dbd2b8e5e46b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------\n","fitting - training...\n","training on whole dataset...\n","predicting...\n","true values  [0 0 0 0 0 0 0 0 0 0]\n","predicted    [0 1 1 0 2 1 2 0 0 2]\n","scoring...\n","Train score =  1.0\n","Test score =  1.0\n","whole set score =  1.0\n","--------------\n","fitting - training...\n","training on whole dataset...\n","predicting...\n","true values  [0 0 0 0 0 0 0 0 0 0]\n","predicted    [0 1 1 0 2 1 2 0 0 2]\n","scoring...\n","Train score =  0.9666666666666667\n","Test score =  0.9833333333333333\n","whole set score =  0.9733333333333334\n","--------------\n","fitting - training...\n","training on whole dataset...\n","predicting...\n","true values  [0 0 0 0 0 0 0 0 0 0]\n","predicted    [0 1 1 0 2 1 2 0 0 2]\n","scoring...\n","Train score =  0.9555555555555556\n","Test score =  0.9833333333333333\n","whole set score =  0.9666666666666667\n"]}]},{"cell_type":"markdown","source":["1. Skorzystałem z dataset \"iris\". Dane zostały podzielone w stosunku 80% do 20%.\n","\n","2. Użyłem 3 klasyfikatory:\n","\n","*   DecisionTreeClassifier\n","*   SVC\n","*   KNeighborsClassifier\n","\n","3. Wytrenowałem oraz obliczyłem metryki dla każdego klasyfikatora (klasyfikator - train score - test score):\n","\n","*   DecisionTreeClassifier - 1.000 \n","*   SVC - 0.966 - 0.983\n","*   KNeighborsClassifier - 0.955 - 0.983\n","\n","SVC, KNeighborsClassifier stworzyły bardzo dobre modele, których metryki na danych testowych wypadły niewiele słabiej niż na danych treningowych. Wśród nich najlepsze okazało się SVC.\n","\n","DecisionTreeClassifier - mamy tutaj do czynienia z overfittingiem. Dla obu rodzajów danych mamy wartość = 1"],"metadata":{"id":"NqE2cViJ_kZU"}}]}